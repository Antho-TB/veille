import sys
import os
import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer, util
import mlflow

# Configuration MLflow
mlflow.set_tracking_uri("http://127.0.0.1:5050")
mlflow.set_experiment("Semantic_Audit_CamemBERT")

# Simulation de l'extraction des donn√©es
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'src')))
from utils.sync_server import get_spreadsheet, find_col, normalize_proof_label

def run_semantic_audit():
    with mlflow.start_run(run_name="CamemBERT_HITL_Audit"):
        print("üîç Lancement de l'Audit S√©mantique (CamemBERT / Sentence-Transformers)...")
        
        # 1. Chargement des donn√©es
        ss = get_spreadsheet()
        ws = ss.worksheet('Base_Active')
        vals = ws.get_all_values()
        head = vals[0]
        rows = vals[1:]
        
        col_idx = find_col(head, 'Preuve de Conformit√© Attendue') or 19
        raw_proofs = sorted(list(set([r[col_idx-1].strip() for r in rows if len(r) >= col_idx and r[col_idx-1].strip()])))
        
        print(f"üìä {len(raw_proofs)} preuves uniques √† analyser.")
        mlflow.log_param("unique_proofs_count", len(raw_proofs))

        # 2. Chargement du mod√®le (Mod√®le multilingue optimis√© pour le fran√ßais)
        # On utilise paraphrase-multilingual car il est plus l√©ger et performant pour la similarit√© s√©mantique pure
        model_name = 'paraphrase-multilingual-MiniLM-L12-v2'
        print(f"üöÄ Chargement du mod√®le {model_name}...")
        model = SentenceTransformer(model_name)
        mlflow.log_param("model_name", model_name)

        # 3. G√©n√©ration des Embeddings
        print("üß† G√©n√©ration des vecteurs s√©mantiques...")
        embeddings = model.encode(raw_proofs, convert_to_tensor=True)
        
        # 4. Calcul de la similarit√© Cosinus
        cosine_scores = util.cos_sim(embeddings, embeddings)
        
        # 5. Extraction des paires √† haute similarit√© (Audit)
        suggestions = []
        threshold = 0.85
        mlflow.log_param("similarity_threshold", threshold)

        for i in range(len(raw_proofs)):
            for j in range(i + 1, len(raw_proofs)):
                score = cosine_scores[i][j].item()
                if score >= threshold:
                    # On v√©rifie si notre heuristique actuelle les fusionne d√©j√†
                    p1, p2 = raw_proofs[i], raw_proofs[j]
                    norm1 = normalize_proof_label(p1)
                    norm2 = normalize_proof_label(p2)
                    
                    already_merged = (norm1 == norm2)
                    
                    suggestions.append({
                        "proof_A": p1,
                        "proof_B": p2,
                        "similarity": round(score, 4),
                        "already_merged_by_heuristic": already_merged,
                        "suggested_canonical": norm1 if len(norm1) < len(norm2) else norm2
                    })

        df_suggestions = pd.DataFrame(suggestions).sort_values(by="similarity", ascending=False)
        
        # 6. Filtrage pour l'arbitrage humain (HITL)
        # On se concentre sur ce que l'heuristique n'a PAS vu
        hitl_candidates = df_suggestions[df_suggestions['already_merged_by_heuristic'] == False]
        
        print(f"üí° {len(hitl_candidates)} fusions potentielles d√©tect√©es par l'Intelligence Artificielle.")
        mlflow.log_metric("new_fusions_suggested", len(hitl_candidates))

        # Export du rapport
        report_path = 'camembert_hits_for_arbitrage.csv'
        hitl_candidates.to_csv(report_path, index=False, encoding='utf-8-sig')
        mlflow.log_artifact(report_path)
        
        print(f"\n‚úÖ Audit termin√©. Rapport g√©n√©r√© : {report_path}")
        print("üëâ Veuillez consulter ce fichier pour valider les fusions sugg√©r√©es.")

if __name__ == "__main__":
    run_semantic_audit()
